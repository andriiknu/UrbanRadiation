{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Conv1D, Flatten, BatchNormalization, GlobalMaxPool1D, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"wdata\\\\train_feature_bin_30_slice.csv\")\n",
    "\n",
    "def get_training_data(df_train):\n",
    "\n",
    "    \n",
    "    target = df_train.iloc[:, -1]\n",
    "    y = to_categorical(target, num_classes=len(np.unique(target)))\n",
    "    x_trn = df_train.iloc[:,1:-1]  \n",
    "\n",
    "    # scale train ==========================================================================================================  \n",
    "    X = x_trn.values\n",
    "    where_are_NaNs = np.isnan(X)\n",
    "    where_are_infs = np.isinf(X)\n",
    "    X[where_are_NaNs] = 0\n",
    "    X[where_are_infs] = 0\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(X)\n",
    "    scaled_train_X = scaler.transform(X)\n",
    "    X = scaled_train_X\n",
    "    X = X.reshape(len(df_train), len(X[0]), 1)\n",
    "\n",
    "    return (X, y)\n",
    "\n",
    "def init_model(num_features):\n",
    "\n",
    "    inp = Input(shape=(num_features, 1))\n",
    "\n",
    "    a = Conv1D(64, 5, activation=\"relu\", kernel_initializer=\"uniform\", )(inp)\n",
    "    a = BatchNormalization()(a)\n",
    "    a = Conv1D(64, 5, activation=\"relu\", kernel_initializer=\"uniform\", )(a)\n",
    "    a = BatchNormalization()(a)\n",
    "    max_pool = GlobalMaxPool1D()(a)\n",
    "\n",
    "    b = Flatten()(inp)\n",
    "    ab = concatenate([ max_pool, b])\n",
    "\n",
    "    a = Dense(128, activation=\"relu\", kernel_initializer=\"uniform\")(ab)\n",
    "    a = Dropout(0.5)(a)\n",
    "    a = Dense(128, activation=\"relu\", kernel_initializer=\"uniform\")(a)\n",
    "\n",
    "    output = Dense(7, activation=\"softmax\", kernel_initializer=\"uniform\")(a)\n",
    "    model = Model(inp, output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ids = df_train.index[df_train['152'] == 1].to_list()\n",
    "all_length = len(_ids)\n",
    "fold_len = int(all_length / 5)\n",
    "\n",
    "init_idx = 0\n",
    "_train_idx = _ids[init_idx: init_idx + fold_len]\n",
    "df_train.loc[_train_idx, 'fold'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ...\n",
       "       '144', '145', '146', '147', '148', '149', '150', '151', '152', 'fold'],\n",
       "      dtype='object', length=154)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
